{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11575288,"sourceType":"datasetVersion","datasetId":7257397},{"sourceId":11591353,"sourceType":"datasetVersion","datasetId":7268529}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Retrieval-Augmented Shopping Assistant - EDA\n\nThis notebook explores the ABO dataset for initial insights.","metadata":{}},{"cell_type":"code","source":"import pandas as pd","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load ABO image dataset\ndf_img = pd.read_csv(\"/kaggle/input/amazon-berkeley-objects/images/metadata/images.csv\")  # or csv if applicable","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 1. Check structure\nprint(df_img.shape)\nprint(df_img.columns)\nprint(df_img.dtypes)\n\n# 2. Check missing values\nprint(df_img.notnull().sum())\n\n# 3. Sample record\ndf_img.sample(5)\n\n# 4. (If possible) display an image\nfrom PIL import Image\nimport matplotlib.pyplot as plt\n\nimg_loc = str(df_img.loc[df_img['path']== '8c/8ccb5859.jpg']['path']).split()[1]\nimg_path = '/kaggle/input/amazon-berkeley-objects/images/small/' + img_loc  # based on image_id field\nimg = Image.open(img_path)\nplt.imshow(img)\nplt.axis('off')\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load ABO metadata dataset\n\nimport os, glob\nfull_metadata = pd.DataFrame()\nfor json_file in glob.glob(\"/kaggle/input/listing/listings/metadata/*.json\"):\n    print('Loading file: ' + json_file + '\\n')\n    df_metadata = pd.read_json(json_file, lines = True)\n    full_metadata = pd.concat([full_metadata, df_metadata])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 1. Check structure\nprint(full_metadata.shape)\nprint(full_metadata.columns)\nprint(full_metadata.dtypes)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 2. Check missing values\nprint(full_metadata.notnull().sum())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"From above, \"finish_type\" column has the lowest number of values present i.e. 1536 out of 147702 product entries.","metadata":{}},{"cell_type":"code","source":"print(full_metadata.loc[full_metadata['item_id'] == 'B07TGZZMDK'])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 3. Sample record\npd.set_option('display.max_colwidth', None)\npd.set_option('display.max_columns', None)\n#full_metadata.sample(5)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"From above, it is clear that:\n1. Only **item_name** column is present for all products.\n2. We will use **item_name** to filter for in scope language - English.","metadata":{}},{"cell_type":"code","source":"# 4. Display an image using image id from the metadata\n\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nprint(full_metadata.loc[full_metadata['main_image_id'] == '81iZlv3bjpL'])\nimg_path = full_metadata.loc[full_metadata['main_image_id'] == '81iZlv3bjpL']\nimg_id = img_path.iloc[0]['main_image_id']\nimg_location = str(df_img.loc[df_img['image_id'] == img_id]['path'])\nimg = Image.open('/kaggle/input/amazon-berkeley-objects/images/small/' + img_location.split()[1])\nplt.imshow(img)\nplt.axis('off')\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Analyse the number of languages supported. US-English in scope only.\ncount_US_lang_key = 0\ncount_prodDesc = 0\ncount_total=0\nlang_set = set()\nfor val in full_metadata['item_name']:\n    count_total += 1\n    for key, value in val[0].items():\n        if(key == 'language_tag'):\n            lang_set.add(value)\nprint(lang_set)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Amongst these, only English language will be used. i.e,\nen_SG,\nen_CA,\nen_AU,\nen_GB, \nen_AE, \nen_US,\nen_IN","metadata":{}},{"cell_type":"code","source":"# Analyse the number of languages supported. US-English in scope only.\ncountTotalProdDesc = 0\ncountTotalEngDesc = 0\nfor val in full_metadata['item_name']:\n    for key, value in val[0].items():\n        if(key == 'language_tag'and value in ('en_SG', 'en_CA','en_AU','en_GB','en_AE','en_US','en_IN')):\n            #list_items = list(val[0].items())\n            #print(list_items[1])\n            countTotalEngDesc += 1\n        countTotalProdDesc += 1 \n\nprint('countTotalEngDesc: ', countTotalEngDesc)\nprint('countTotalProdDesc: ', countTotalProdDesc)\nprint('Percentage of data under scope:', countTotalEngDesc/countTotalProdDesc * 100)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Reduce the metadata to in scope languages only\n\n# Step 1: Store indices of rows that match the language criteria\nmatching_indices = []\n\nvalid_languages = {'en_SG', 'en_CA','en_AU','en_GB','en_AE','en_US','en_IN'}\n\nfor idx, row in full_metadata.iterrows():\n    item_name = row['item_name']\n    if isinstance(item_name, list):\n        if any(d.get('language_tag') in valid_languages for d in item_name if isinstance(d, dict)):\n            matching_indices.append(idx)\n\n# Step 2: Filter all at once using .iloc\ninScopeMetadata = full_metadata.iloc[matching_indices].reset_index(drop=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def auto_flatten_json_columns(df, keys_to_try=['value', 'name']):\n    \"\"\"\n    Detects and flattens columns containing lists of JSON objects,\n    extracting specified keys.\n    Adds new columns with a `_flat` suffix.\n    \"\"\"\n    def extract_from_list(ld, keys):\n        if isinstance(ld, list):\n            for key in keys:\n                values = [str(d.get(key)) for d in ld if isinstance(d, dict) and key in d]\n                if values:  # found at least one valid value\n                    return \", \".join(values)\n        return None\n\n    # Track flattened columns\n    flattened = []\n\n    for col in df.columns:\n        sample = df[col].iloc[0]\n        if isinstance(sample, list) and all(isinstance(i, dict) for i in sample):\n            flat_col = f\"{col}_flat\"\n            df[flat_col] = df[col].apply(lambda x: extract_from_list(x, keys_to_try))\n            flattened.append(flat_col)\n\n    return df, flattened","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(inScopeMetadata.shape)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"inScopeMetadata, flattened_cols = auto_flatten_json_columns(inScopeMetadata)\nprint(\"Flattened columns:\", flattened_cols)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(inScopeMetadata.columns)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Construct the Embedding Input Text\n\nembedding_cols = [\n    'item_name_flat',\n    'brand_flat',\n    'product_type_flat',\n    'material_flat',\n    'bullet_point_flat',\n    'color_flat',\n    'item_keywords_flat'\n]\n\ninScopeMetadata['embedding_input'] = inScopeMetadata[embedding_cols].fillna('').agg(' '.join, axis=1)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"inScopeMetadata.notnull().sum()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Generate Embeddings from embedding_input\n\n!pip install -U sentence-transformers","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Load model and encode\n\nfrom sentence_transformers import SentenceTransformer\n\n# Load the model (compact + effective)\nmodel = SentenceTransformer('all-MiniLM-L6-v2')\n\n# Generate dense embeddings (512-dimensional vectors)\nembedding_list = model.encode(\n    inScopeMetadata['embedding_input'].tolist(),\n    show_progress_bar=True,\n    convert_to_numpy=True\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Attach to the dataframe\n\nimport numpy as np\n\n# Save as separate column or matrix\ninScopeMetadata['embedding_vector'] = list(embedding_list)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}