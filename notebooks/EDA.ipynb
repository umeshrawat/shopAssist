{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11575288,"sourceType":"datasetVersion","datasetId":7257397},{"sourceId":11591353,"sourceType":"datasetVersion","datasetId":7268529}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Retrieval-Augmented Shopping Assistant - EDA\n\nThis notebook explores the ABO dataset for initial insights.","metadata":{}},{"cell_type":"code","source":"import pandas as pd","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load ABO image dataset\ndf_img = pd.read_csv(\"/kaggle/input/amazon-berkeley-objects/images/metadata/images.csv\")  # or csv if applicable","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 1. Check structure\nprint(df_img.shape)\nprint(df_img.columns)\nprint(df_img.dtypes)\n\n# 2. Check missing values\nprint(df_img.notnull().sum())\n\n# 3. Sample record\ndf_img.sample(5)\n\n# 4. (If possible) display an image\nfrom PIL import Image\nimport matplotlib.pyplot as plt\n\nimg_loc = str(df_img.loc[df_img['path']== '8c/8ccb5859.jpg']['path']).split()[1]\nimg_path = '/kaggle/input/amazon-berkeley-objects/images/small/' + img_loc  # based on image_id field\nimg = Image.open(img_path)\nplt.imshow(img)\nplt.axis('off')\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load ABO metadata dataset\n\nimport os, glob\nfull_metadata = pd.DataFrame()\nfor json_file in glob.glob(\"/kaggle/input/listing/listings/metadata/*.json\"):\n    print('Loading file: ' + json_file + '\\n')\n    df_metadata = pd.read_json(json_file, lines = True)\n    full_metadata = pd.concat([full_metadata, df_metadata])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 1. Check structure\nprint(full_metadata.shape)\nprint(full_metadata.columns)\nprint(full_metadata.dtypes)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 2. Check missing values\nfull_metadata.isna().sum().sort_values(ascending=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"From above, \"finish_type\" column has the lowest number of values present i.e. 1536 (147702 - 146166)  out of 147702 product entries.","metadata":{}},{"cell_type":"code","source":"#Find duplicate item_id rows\n\nduplicate_counts = full_metadata['item_id'].value_counts()\nduplicate_counts = duplicate_counts[duplicate_counts > 1]\nprint(duplicate_counts)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"There are duplicates but analyising one of the item_id below.","metadata":{}},{"cell_type":"code","source":"full_metadata.loc[full_metadata['item_id'] == 'B01BC2TBZ4']","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"There are duplicate item_ids, because of multiple language support. We will remove duplicates after creating \na scoped dataframe for supported language.","metadata":{}},{"cell_type":"code","source":"# 3. Sample record\npd.set_option('display.max_colwidth', None)\npd.set_option('display.max_columns', None)\n#full_metadata.sample(5)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"From above, it is clear that:\n1. Only **item_name** column is present for all products.\n2. We will use **item_name** to filter for in scope language - English.","metadata":{}},{"cell_type":"code","source":"# 4. Display an image using image id from the metadata\n\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nprint(full_metadata.loc[full_metadata['main_image_id'] == '413jqtAkNSL'])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"img_row = full_metadata.loc[full_metadata['main_image_id'] == '413jqtAkNSL']\nimg_id = img_row.iloc[0]['main_image_id']\nimg_location = str(df_img.loc[df_img['image_id'] == img_id]['path'])\nimg = Image.open('/kaggle/input/amazon-berkeley-objects/images/small/' + img_location.split()[1])\nplt.imshow(img)\nplt.axis('off')\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Analyse the number of languages supported. US-English in scope only.\ncount_US_lang_key = 0\ncount_prodDesc = 0\ncount_total=0\nlang_set = set()\nfor val in full_metadata['item_name']:\n    count_total += 1\n    for key, value in val[0].items():\n        if(key == 'language_tag'):\n            lang_set.add(value)\nprint(lang_set)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Amongst these, only English language will be used. i.e,\nen_SG,\nen_CA,\nen_AU,\nen_GB, \nen_AE, \nen_US,\nen_IN","metadata":{}},{"cell_type":"code","source":"valid_languages = {'en_SG', 'en_CA', 'en_AU', 'en_GB', 'en_AE', 'en_US', 'en_IN'}\n\ncountTotalProdDesc = 0\ncountTotalEngDesc = 0\n\nfor val in full_metadata['item_name']:\n    if isinstance(val, list):\n        for item in val:\n            if isinstance(item, dict):\n                countTotalProdDesc += 1\n                if item.get('language_tag') in valid_languages:\n                    countTotalEngDesc += 1\n\nprint('Total language-tagged entries (all languages):', countTotalProdDesc)\nprint('Total in-scope English entries:', countTotalEngDesc)\nprint('Percentage of data under scope:', round(countTotalEngDesc / countTotalProdDesc * 100, 2), '%')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Reduce the metadata to in scope languages only\ndef has_valid_language(item_name):\n    if isinstance(item_name, list):\n        return any(\n            isinstance(entry, dict) and entry.get('language_tag') in valid_languages\n            for entry in item_name\n        )\n    return False\n\ninScopeMetadata = full_metadata[full_metadata['item_name'].apply(has_valid_language)].reset_index(drop=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(inScopeMetadata.shape)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from collections import Counter\n\nlang_counter = Counter()\n\nfor val in full_metadata['item_name']:\n    if isinstance(val, list):\n        for item in val:\n            if isinstance(item, dict):\n                lang = item.get('language_tag')\n                if lang:\n                    lang_counter[lang] += 1\n\n# Convert to sorted list\nsorted_langs = sorted(lang_counter.items(), key=lambda x: x[1], reverse=True)\n\n# Print\nprint(\"Language-wise distribution in `item_name` field:\\n\")\nfor lang, count in sorted_langs:\n    print(f\"{lang}: {count}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def get_first_valid_lang(item_name):\n    if isinstance(item_name, list):\n        for entry in item_name:\n            if isinstance(entry, dict) and entry.get('language_tag') in valid_languages:\n                return entry['language_tag']\n    return None\n\nfull_metadata['language_matched'] = full_metadata['item_name'].apply(get_first_valid_lang)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(f\"Total rows with valid English variants: {len(inScopeMetadata)} / {len(full_metadata)}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Find duplicate item_id rows\n\nduplicate_counts = inScopeMetadata['item_id'].value_counts()\nduplicate_counts = duplicate_counts[duplicate_counts > 1]\nprint(duplicate_counts)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"inScopeMetadata.loc[inScopeMetadata['item_id'] == 'B07WC622LH']","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def auto_flatten_json_columns(df, keys_to_try=['value', 'name', 'node_name']):\n    \"\"\"\n    Detects and flattens columns containing lists of JSON objects,\n    extracting specified keys.\n    Adds new columns with a `_flat` suffix.\n    \"\"\"\n    def extract_from_list(ld, keys):\n        if isinstance(ld, list):\n            for key in keys:\n                values = [str(d.get(key)) for d in ld if isinstance(d, dict) and key in d]\n                if values:  # found at least one valid value\n                    return \", \".join(values)\n        return None\n\n    # Track flattened columns\n    flattened = []\n\n    for col in df.columns:\n        sample = df[col].iloc[0]\n        if isinstance(sample, list) and all(isinstance(i, dict) for i in sample):\n            flat_col = f\"{col}_flat\"\n            df[flat_col] = df[col].apply(lambda x: extract_from_list(x, keys_to_try))\n            flattened.append(flat_col)\n\n    return df, flattened","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(inScopeMetadata.shape)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"inScopeMetadata, flattened_cols = auto_flatten_json_columns(inScopeMetadata)\nprint(\"Flattened columns:\", flattened_cols)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(inScopeMetadata.columns)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(full_metadata.shape)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"full_metadata, flattened_cols = auto_flatten_json_columns(full_metadata)\nprint(\"Flattened columns:\", flattened_cols)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(full_metadata.shape)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(full_metadata.dtypes)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 2. Check missing values\nprint(full_metadata.notnull().sum())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(full_metadata.index[:10])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"full_metadata = full_metadata.reset_index(drop=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(full_metadata.loc[1])  # Row with index label 1","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(full_metadata.columns)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#1. Top 10 Brands\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ntop_brands = full_metadata['brand_flat'].value_counts().head(10)\n\nplt.figure(figsize=(10, 6))\nsns.barplot(x=top_brands.values, y=top_brands.index, palette='viridis')\nplt.title(\"Top 10 Brands by Frequency\")\nplt.xlabel(\"Count\")\nplt.ylabel(\"Brand\")\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Top 10 product types\n\ntop_types = full_metadata['product_type_flat'].value_counts().head(10)\n\nplt.figure(figsize=(10, 6))\nsns.barplot(x=top_types.values, y=top_types.index, palette='mako')\nplt.title(\"Top 10 Product Types\")\nplt.xlabel(\"Count\")\nplt.ylabel(\"Product Type\")\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Word cloud from bullet_point information\n\nfrom wordcloud import WordCloud\n\ntext = \" \".join(full_metadata['bullet_point_flat'].dropna().astype(str).values)\nwordcloud = WordCloud(width=800, height=400, background_color='white').generate(text)\n\nplt.figure(figsize=(12, 6))\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis('off')\nplt.title(\"Common Words in Bullet Points\")\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Word cloud from node information\n\nfrom wordcloud import WordCloud\n\ntext = \" \".join(full_metadata['node_flat'].dropna().astype(str).values)\nwordcloud = WordCloud(width=800, height=400, background_color='white').generate(text)\n\nplt.figure(figsize=(12, 6))\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis('off')\nplt.title(\"Common Words in Node\")\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(10, 6))\nsns.countplot(data=full_metadata, x='domain_name', order=full_metadata['domain_name'].value_counts().index)\nplt.title(\"Items per Domain\")\nplt.xlabel(\"Domain\")\nplt.ylabel(\"Count\")\nplt.xticks(rotation=45)\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Above plots show:\n1. More than half of the items are on \"Amazon\" marketplace.\n2. Cellular phone Case, Shoes, Grocery are top 3 product types.\n3. Amazon.in accounts for more than half of listings.\n4. Words around mobile accessories dominate the product's catefories description column (node).\n5. Multiple languages are supported per product. Languages list:\n{'ko_KR', 'es_MX', 'zh_TW', 'sv_SE', 'en_AU', 'fr_CA', 'en_CA', 'he_IL', 'es_US', 'kn_IN', 'tr_TR', 'hi_IN', 'zh_CN', 'en_GB', 'nl_NL', 'pt_BR', 'fr_FR', 'te_IN', 'ja_JP', 'en_IN', 'es_ES', 'en_US', 'ar_AE', 'en_SG', 'ml_IN', 'en_AE', 'cs_CZ', 'it_IT', 'pl_PL', 'de_DE'}\n\nThe full_metadata will be used","metadata":{}},{"cell_type":"code","source":"#Serialize to parquet/persistent storage\n\ninScopeMetadata.to_parquet(\"inScopeMetadata_with_embeddings.parquet\", index=False)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"With above copy, we have:\n\ninScopeMetadata_with_embeddings.parquet → all metadata + embedding inputs","metadata":{}}]}