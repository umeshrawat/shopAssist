{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11644350,"sourceType":"datasetVersion","datasetId":7306864}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"834a5add","cell_type":"markdown","source":"\n# Retrieval-Augmented Shopping Assistant - Embeddings Experimentations","metadata":{}},{"id":"431048c6-a313-4684-a8cc-9b147a20ad12","cell_type":"code","source":"# Generate Embeddings from embedding_input\n\n!pip install -U sentence-transformers","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T17:35:20.598286Z","iopub.execute_input":"2025-05-04T17:35:20.598581Z","iopub.status.idle":"2025-05-04T17:36:48.522616Z","shell.execute_reply.started":"2025-05-04T17:35:20.598552Z","shell.execute_reply":"2025-05-04T17:36:48.521777Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (3.4.1)\nCollecting sentence-transformers\n  Downloading sentence_transformers-4.1.0-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.51.1)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\nRequirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.5.1+cu124)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.2.2)\nRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.15.2)\nRequirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.30.2)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.1.0)\nRequirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.13.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.2)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.11.0->sentence-transformers)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.11.0->sentence-transformers)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.11.0->sentence-transformers)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.11.0->sentence-transformers)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.11.0->sentence-transformers)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.11.0->sentence-transformers)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.2)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (2.4.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.1.31)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.2.0)\nDownloading sentence_transformers-4.1.0-py3-none-any.whl (345 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m345.7/345.7 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m72.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, sentence-transformers\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.8.93\n    Uninstalling nvidia-nvjitlink-cu12-12.8.93:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.8.93\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.9.90\n    Uninstalling nvidia-curand-cu12-10.3.9.90:\n      Successfully uninstalled nvidia-curand-cu12-10.3.9.90\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.3.3.83\n    Uninstalling nvidia-cufft-cu12-11.3.3.83:\n      Successfully uninstalled nvidia-cufft-cu12-11.3.3.83\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.8.4.1\n    Uninstalling nvidia-cublas-cu12-12.8.4.1:\n      Successfully uninstalled nvidia-cublas-cu12-12.8.4.1\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.8.93\n    Uninstalling nvidia-cusparse-cu12-12.5.8.93:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.8.93\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.3.90\n    Uninstalling nvidia-cusolver-cu12-11.7.3.90:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.3.90\n  Attempting uninstall: sentence-transformers\n    Found existing installation: sentence-transformers 3.4.1\n    Uninstalling sentence-transformers-3.4.1:\n      Successfully uninstalled sentence-transformers-3.4.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npylibcugraph-cu12 24.12.0 requires pylibraft-cu12==24.12.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 24.12.0 requires rmm-cu12==24.12.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 sentence-transformers-4.1.0\n","output_type":"stream"}],"execution_count":1},{"id":"51103b79-d2d6-41ab-9549-61d5224b8199","cell_type":"code","source":"# Use the parquet file generated in EDA phase.\n\nimport pandas as pd\n\ninScopeMetadata = pd.read_parquet(\"/kaggle/input/abo-english-metadata-parquet/inScopeMetadata_with_embeddings.parquet\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T17:38:46.974903Z","iopub.execute_input":"2025-05-04T17:38:46.975527Z","iopub.status.idle":"2025-05-04T17:39:01.192983Z","shell.execute_reply.started":"2025-05-04T17:38:46.975496Z","shell.execute_reply":"2025-05-04T17:39:01.192434Z"}},"outputs":[],"execution_count":2},{"id":"d9112a5e-9fe8-4f6a-9e7a-1a4b07728be0","cell_type":"code","source":"# check the type before resuming.\n\ntype(inScopeMetadata['embedding_vector'].iloc[0])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T17:39:04.121051Z","iopub.execute_input":"2025-05-04T17:39:04.121576Z","iopub.status.idle":"2025-05-04T17:39:04.139542Z","shell.execute_reply.started":"2025-05-04T17:39:04.121548Z","shell.execute_reply":"2025-05-04T17:39:04.138736Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"numpy.ndarray"},"metadata":{}}],"execution_count":3},{"id":"89082ffa-f65a-46e5-aca9-107ab19ebf6b","cell_type":"code","source":"print(inScopeMetadata.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T17:50:54.184639Z","iopub.execute_input":"2025-05-04T17:50:54.184945Z","iopub.status.idle":"2025-05-04T17:50:54.189334Z","shell.execute_reply.started":"2025-05-04T17:50:54.184914Z","shell.execute_reply":"2025-05-04T17:50:54.188413Z"}},"outputs":[{"name":"stdout","text":"(122734, 41)\n","output_type":"stream"}],"execution_count":8},{"id":"7a20b64d-42f9-471b-b730-49b867f3cda0","cell_type":"code","source":"inScopeMetadata.sample(1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T17:50:58.149185Z","iopub.execute_input":"2025-05-04T17:50:58.149899Z","iopub.status.idle":"2025-05-04T17:50:58.211237Z","shell.execute_reply.started":"2025-05-04T17:50:58.149871Z","shell.execute_reply":"2025-05-04T17:50:58.210600Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"                                                   brand  \\\n64145  [{'language_tag': 'en_IN', 'value': 'Amazon Br...   \n\n                                            bullet_point  \\\n64145  [{'language_tag': 'en_IN', 'value': '3D Printe...   \n\n                                                   color     item_id  \\\n64145  [{'language_tag': 'en_IN', 'standardized_value...  B07TRX487W   \n\n                                               item_name  \\\n64145  [{'alternate_representations': None, 'language...   \n\n                                             item_weight material  \\\n64145  [{'normalized_value': {'unit': 'pounds', 'valu...     None   \n\n                                              model_name  \\\n64145  [{'language_tag': 'en_IN', 'value': 'Oppo F11 ...   \n\n                        model_number                        product_type  ...  \\\n64145  [{'value': 'gz8637-SL40780'}]  [{'value': 'CELLULAR_PHONE_CASE'}]  ...   \n\n                                          item_name_flat item_weight_flat  \\\n64145  Amazon Brand - Solimo Designer Multicolor Circ...               50   \n\n      material_flat model_name_flat model_number_flat    product_type_flat  \\\n64145          None    Oppo F11 Pro    gz8637-SL40780  CELLULAR_PHONE_CASE   \n\n                                      item_keywords_flat node_flat  \\\n64145  mobile cover, back cover, mobile case, phone c...      None   \n\n                                         embedding_input  \\\n64145  Amazon Brand - Solimo Designer Multicolor Circ...   \n\n                                        embedding_vector  \n64145  [-0.112759896, 0.02776274, 0.032392133, -0.028...  \n\n[1 rows x 41 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>brand</th>\n      <th>bullet_point</th>\n      <th>color</th>\n      <th>item_id</th>\n      <th>item_name</th>\n      <th>item_weight</th>\n      <th>material</th>\n      <th>model_name</th>\n      <th>model_number</th>\n      <th>product_type</th>\n      <th>...</th>\n      <th>item_name_flat</th>\n      <th>item_weight_flat</th>\n      <th>material_flat</th>\n      <th>model_name_flat</th>\n      <th>model_number_flat</th>\n      <th>product_type_flat</th>\n      <th>item_keywords_flat</th>\n      <th>node_flat</th>\n      <th>embedding_input</th>\n      <th>embedding_vector</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>64145</th>\n      <td>[{'language_tag': 'en_IN', 'value': 'Amazon Br...</td>\n      <td>[{'language_tag': 'en_IN', 'value': '3D Printe...</td>\n      <td>[{'language_tag': 'en_IN', 'standardized_value...</td>\n      <td>B07TRX487W</td>\n      <td>[{'alternate_representations': None, 'language...</td>\n      <td>[{'normalized_value': {'unit': 'pounds', 'valu...</td>\n      <td>None</td>\n      <td>[{'language_tag': 'en_IN', 'value': 'Oppo F11 ...</td>\n      <td>[{'value': 'gz8637-SL40780'}]</td>\n      <td>[{'value': 'CELLULAR_PHONE_CASE'}]</td>\n      <td>...</td>\n      <td>Amazon Brand - Solimo Designer Multicolor Circ...</td>\n      <td>50</td>\n      <td>None</td>\n      <td>Oppo F11 Pro</td>\n      <td>gz8637-SL40780</td>\n      <td>CELLULAR_PHONE_CASE</td>\n      <td>mobile cover, back cover, mobile case, phone c...</td>\n      <td>None</td>\n      <td>Amazon Brand - Solimo Designer Multicolor Circ...</td>\n      <td>[-0.112759896, 0.02776274, 0.032392133, -0.028...</td>\n    </tr>\n  </tbody>\n</table>\n<p>1 rows Ã— 41 columns</p>\n</div>"},"metadata":{}}],"execution_count":9},{"id":"0a85882f-4958-4bae-9c5c-27682b557c37","cell_type":"code","source":"duplicate_counts = inScopeMetadata['item_id'].value_counts()\nduplicate_counts = duplicate_counts[duplicate_counts > 1]\nprint(duplicate_counts)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T17:51:18.560538Z","iopub.execute_input":"2025-05-04T17:51:18.561021Z","iopub.status.idle":"2025-05-04T17:51:18.593843Z","shell.execute_reply.started":"2025-05-04T17:51:18.560998Z","shell.execute_reply":"2025-05-04T17:51:18.593121Z"}},"outputs":[{"name":"stdout","text":"item_id\nB07WC622LH    28\nB0746MMVXW    28\nB07797D9MW    27\nB073S3R169    26\nB01928HSB4    26\n              ..\nB07GN662BP     7\nB07RRWD8QB     7\nB07HFTZ8YW     7\nB07RR3RFHT     7\nB01719EX2S     7\nName: count, Length: 9225, dtype: int64\n","output_type":"stream"}],"execution_count":10},{"id":"44199560-1e6b-4195-a59c-64577f47a43f","cell_type":"code","source":"!pip install faiss-cpu --quiet","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T17:51:37.958425Z","iopub.execute_input":"2025-05-04T17:51:37.959231Z","iopub.status.idle":"2025-05-04T17:51:43.218945Z","shell.execute_reply.started":"2025-05-04T17:51:37.959205Z","shell.execute_reply":"2025-05-04T17:51:43.217842Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m55.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":12},{"id":"b0b6d8c1-9427-457d-9a4b-3aa3cea13b2f","cell_type":"code","source":"#Load model and encode\n\nfrom sentence_transformers import SentenceTransformer\n\n# Load the model (compact + effective)\nmodel = SentenceTransformer('all-MiniLM-L12-v2')\n\n# Generate dense embeddings (512-dimensional vectors)\nembedding_list = model.encode(\n    inScopeMetadata['embedding_input'].tolist(),\n    show_progress_bar=True,\n    convert_to_numpy=True\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T18:37:27.763867Z","iopub.execute_input":"2025-05-04T18:37:27.764178Z","iopub.status.idle":"2025-05-04T18:42:33.249655Z","shell.execute_reply.started":"2025-05-04T18:37:27.764156Z","shell.execute_reply":"2025-05-04T18:42:33.248981Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/3836 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a1471679ac9849079fdd15ac473c7339"}},"metadata":{}}],"execution_count":19},{"id":"58b16dbc-cde4-457e-ae97-20d391775f44","cell_type":"code","source":"# Attach to the dataframe\n\nimport numpy as np\n\n# Save as separate column or matrix\ninScopeMetadata['embedding_vector'] = list(embedding_list)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T18:43:31.165088Z","iopub.execute_input":"2025-05-04T18:43:31.165389Z","iopub.status.idle":"2025-05-04T18:43:31.214325Z","shell.execute_reply.started":"2025-05-04T18:43:31.165368Z","shell.execute_reply":"2025-05-04T18:43:31.213369Z"}},"outputs":[],"execution_count":20},{"id":"b4d3c409-9067-4138-a3e4-e4e06cb43be3","cell_type":"code","source":"import numpy as np\n\nembedding_matrix = np.vstack(embedding_list)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T18:43:42.250720Z","iopub.execute_input":"2025-05-04T18:43:42.251041Z","iopub.status.idle":"2025-05-04T18:43:42.500223Z","shell.execute_reply.started":"2025-05-04T18:43:42.251005Z","shell.execute_reply":"2025-05-04T18:43:42.499421Z"}},"outputs":[],"execution_count":21},{"id":"d0616640-cf82-4ad2-b0d2-8a84f9ea8c6e","cell_type":"code","source":"print(embedding_matrix.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T18:43:45.499464Z","iopub.execute_input":"2025-05-04T18:43:45.500035Z","iopub.status.idle":"2025-05-04T18:43:45.504427Z","shell.execute_reply.started":"2025-05-04T18:43:45.500014Z","shell.execute_reply":"2025-05-04T18:43:45.503460Z"}},"outputs":[{"name":"stdout","text":"(122734, 384)\n","output_type":"stream"}],"execution_count":22},{"id":"bee84441-4c7f-4404-bcef-444f94b9ddb7","cell_type":"code","source":"# Create vector index\n\nimport faiss\n\ndim = embedding_matrix.shape[1]\nfaiss_index = faiss.IndexFlatL2(dim)\nfaiss_index.add(embedding_matrix)  # ğŸ”¥ fast vector search","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T18:43:52.512649Z","iopub.execute_input":"2025-05-04T18:43:52.513328Z","iopub.status.idle":"2025-05-04T18:43:52.697218Z","shell.execute_reply.started":"2025-05-04T18:43:52.513305Z","shell.execute_reply":"2025-05-04T18:43:52.696641Z"}},"outputs":[],"execution_count":23},{"id":"0b324299-7937-4588-9800-db65fb075733","cell_type":"code","source":"np.save(\"embedding_matrix.npy\", embedding_matrix)\n#embedding_matrix = np.load(\"embedding_matrix.npy\")\nfaiss.write_index(index, \"faiss_index.index\")\n# index = faiss.read_index(\"faiss_index.index\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T04:05:14.470799Z","iopub.execute_input":"2025-05-02T04:05:14.471120Z","iopub.status.idle":"2025-05-02T04:05:14.728412Z","shell.execute_reply.started":"2025-05-02T04:05:14.471101Z","shell.execute_reply":"2025-05-02T04:05:14.727851Z"}},"outputs":[],"execution_count":14},{"id":"7f2c70d2-18f8-4ba1-9a68-ada7678e93cf","cell_type":"markdown","source":"With above copies, we have:\n\nfaiss_index.index â†’ FAISS binary index\ninScopeMetadata_with_embeddings.parquet â†’ all metadata + embedding inputs\nembedding_matrix.npy â†’ optional fallback","metadata":{}},{"id":"629f54d2-8659-4884-9060-b1cde5b885eb","cell_type":"code","source":"\n# 3. Sample record\npd.set_option('display.max_colwidth', None)\npd.set_option('display.max_columns', None)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T18:43:58.345616Z","iopub.execute_input":"2025-05-04T18:43:58.345862Z","iopub.status.idle":"2025-05-04T18:43:58.349602Z","shell.execute_reply.started":"2025-05-04T18:43:58.345845Z","shell.execute_reply":"2025-05-04T18:43:58.348866Z"}},"outputs":[],"execution_count":24},{"id":"83fa2965-bd36-4642-9860-67cea6b4ec56","cell_type":"code","source":"import numpy as np\nimport faiss\nimport pandas as pd\nfrom collections import OrderedDict\n\ndef rerank_faiss_results(query_embedding, faiss_index, metadata_df, top_k=50, final_k=10):\n    \"\"\"\n    query_embedding: np.array of shape (384,) from all-MiniLM-L12-v2\n    faiss_index: FAISS index object\n    metadata_df: DataFrame with a column 'item_id' aligned by FAISS vector index\n    top_k: how many closest vectors to fetch initially\n    final_k: how many unique item_ids to return\n    \"\"\"\n\n    # Reshape query embedding\n    query_embedding = np.array([query_embedding]).astype('float32')\n\n    # Get top_k nearest embeddings\n    D, I = faiss_index.search(query_embedding, top_k)\n    distances = D[0]\n    indices = I[0]\n\n    # Track top unique items\n    seen_item_ids = OrderedDict()\n    \n    for dist, idx in zip(distances, indices):\n        item_id = metadata_df.iloc[idx]['item_id']\n        if item_id not in seen_item_ids:\n            seen_item_ids[item_id] = {\n                'item_id': item_id,\n                'index': idx,\n                'distance': dist,\n                'metadata': metadata_df.iloc[idx].to_dict()\n            }\n        if len(seen_item_ids) >= final_k:\n            break\n\n    # Convert to DataFrame or list\n    results = list(seen_item_ids.values())\n    return results","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T18:44:00.741118Z","iopub.execute_input":"2025-05-04T18:44:00.741393Z","iopub.status.idle":"2025-05-04T18:44:00.747383Z","shell.execute_reply.started":"2025-05-04T18:44:00.741374Z","shell.execute_reply":"2025-05-04T18:44:00.746706Z"}},"outputs":[],"execution_count":25},{"id":"90660c54-bbfc-4eb8-8efd-5fe8b9d173c3","cell_type":"code","source":"print(inScopeMetadata.columns.tolist())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T18:44:04.332127Z","iopub.execute_input":"2025-05-04T18:44:04.332705Z","iopub.status.idle":"2025-05-04T18:44:04.336971Z","shell.execute_reply.started":"2025-05-04T18:44:04.332682Z","shell.execute_reply":"2025-05-04T18:44:04.336256Z"}},"outputs":[{"name":"stdout","text":"['brand', 'bullet_point', 'color', 'item_id', 'item_name', 'item_weight', 'material', 'model_name', 'model_number', 'product_type', 'main_image_id', 'other_image_id', 'item_keywords', 'country', 'marketplace', 'domain_name', 'node', 'style', 'item_dimensions', 'model_year', 'color_code', 'spin_id', '3dmodel_id', 'fabric_type', 'item_shape', 'pattern', 'product_description', 'finish_type', 'brand_flat', 'bullet_point_flat', 'color_flat', 'item_name_flat', 'item_weight_flat', 'material_flat', 'model_name_flat', 'model_number_flat', 'product_type_flat', 'item_keywords_flat', 'node_flat', 'embedding_input', 'embedding_vector']\n","output_type":"stream"}],"execution_count":26},{"id":"78f58e98-bd41-49a3-88f3-9d47c2ac4481","cell_type":"code","source":"from sentence_transformers import SentenceTransformer\n\nmodel = SentenceTransformer('all-MiniLM-L12-v2')\nquery = \"Shoe\"\nquery_embedding = model.encode(query)\n\ntop_results = rerank_faiss_results(query_embedding, faiss_index, inScopeMetadata, top_k=50, final_k=10)\n\nfor res in top_results:\n    print(res['item_id'], res['distance'], res['metadata']['item_name_flat'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T18:46:31.803520Z","iopub.execute_input":"2025-05-04T18:46:31.803786Z","iopub.status.idle":"2025-05-04T18:46:33.350061Z","shell.execute_reply.started":"2025-05-04T18:46:31.803766Z","shell.execute_reply":"2025-05-04T18:46:33.349295Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5e4d846a03fe4626bd744b1ba7f47415"}},"metadata":{}},{"name":"stdout","text":"B07D451GP9 0.7125936 Amazon Brand - find. Women's Ankle boots\nB07WKBW4RR 0.78247225 find. Women's Lace-s-2-46 Open Toe Sandals\nB07KMRBT8Q 0.7946671 find. Round Toe Block Heel Leather Court, Womenâ€™s Closed-Toe Pumps\nB0812BSW74 0.79647666 find. Men's Cupsole Boat Shoe, Blue Navy Suede, women 2\n","output_type":"stream"}],"execution_count":30},{"id":"a1da63a9-3025-4e6c-a000-c87c52c44b59","cell_type":"code","source":"from openai import OpenAI\n\ndef openai_chat_completion(prompt, model=\"gpt-4\", temperature=0.7, max_tokens=300):\n    client = OpenAI()\n\n    response = client.chat.completions.create(\n        model=\"gpt-4\",\n        messages=[\n            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ],\n        temperature=0.7,\n        max_tokens=300\n    )\n    \n    return response['choices'][0]['message']['content'].strip()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T19:03:30.329950Z","iopub.execute_input":"2025-05-04T19:03:30.330729Z","iopub.status.idle":"2025-05-04T19:03:30.335786Z","shell.execute_reply.started":"2025-05-04T19:03:30.330704Z","shell.execute_reply":"2025-05-04T19:03:30.334857Z"}},"outputs":[],"execution_count":39},{"id":"61f83408-37cc-4578-a2c7-7d1decf6a6c4","cell_type":"code","source":"def generate_image_url(main_image_id):\n    # Update this to your actual image bucket/path\n    base_url = \"https://amazon-berkeley-objects.s3.amazonaws.com/images/\"\n    return f\"{base_url}{main_image_id}.jpg\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T18:58:46.967483Z","iopub.execute_input":"2025-05-04T18:58:46.968116Z","iopub.status.idle":"2025-05-04T18:58:46.972180Z","shell.execute_reply.started":"2025-05-04T18:58:46.968054Z","shell.execute_reply":"2025-05-04T18:58:46.971266Z"}},"outputs":[],"execution_count":36},{"id":"fea0cc2c-23ca-4366-9602-cca09572f2f0","cell_type":"code","source":"def rag_response(query, faiss_index, model, metadata_df, top_k=50, final_k=5):\n    # Embed query\n    query_embedding = model.encode(query)\n\n    # Retrieve top results\n    top_items = rerank_faiss_results(query_embedding, faiss_index, metadata_df, top_k=top_k, final_k=final_k)\n\n    # Build context\n    context_snippets = []\n    for item in top_items:\n        meta = item['metadata']\n        image_url = generate_image_url(meta.get('main_image_id', ''))\n        snippet = (\n            f\"Item: {meta.get('item_name_flat', '')}\\n\"\n            f\"Brand: {meta.get('brand_flat', '')}\\n\"\n            f\"Color: {meta.get('color_flat', '')}\\n\"\n            f\"Material: {meta.get('material_flat', '')}\\n\"\n            f\"Style: {meta.get('style', '')}\\n\"\n            f\"Description: {meta.get('product_description', '') or meta.get('bullet_point_flat', '')}\\n\"\n            f\"Image: {image_url}\\n\"\n        )\n        context_snippets.append(snippet.strip())\n\n    context = \"\\n\\n\".join(context_snippets)\n\n    # Prompt\n    prompt = f\"\"\"\nYou are a shopping assistant. Based on the following product data, recommend options to answer the query: \"{query}\"\n\n{context}\n\nList the product name, brand, and one-line summary for each. Do not hallucinate or invent items.\n\"\"\"\n\n    return openai_chat_completion(prompt)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T18:58:48.762789Z","iopub.execute_input":"2025-05-04T18:58:48.763404Z","iopub.status.idle":"2025-05-04T18:58:48.769091Z","shell.execute_reply.started":"2025-05-04T18:58:48.763379Z","shell.execute_reply":"2025-05-04T18:58:48.768226Z"}},"outputs":[],"execution_count":37},{"id":"8f44590a-d1e1-4d4d-bca5-4774c6287f1b","cell_type":"code","source":"import os\nos.environ[\"OPENAI_API_KEY\"] = \"sk-...\"  # only if not already set","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T19:07:22.336471Z","iopub.execute_input":"2025-05-04T19:07:22.336751Z","iopub.status.idle":"2025-05-04T19:07:22.340990Z","shell.execute_reply.started":"2025-05-04T19:07:22.336732Z","shell.execute_reply":"2025-05-04T19:07:22.340155Z"}},"outputs":[],"execution_count":41},{"id":"82095bb7-f42a-49d8-91bd-0546f09f0bbe","cell_type":"code","source":"from sentence_transformers import SentenceTransformer\n\nmodel = SentenceTransformer('all-MiniLM-L12-v2')\nquery = \"Shoe\"\n\ntop_results = rag_response(query, faiss_index, model, inScopeMetadata, top_k=50, final_k=10)\n\nfor res in top_results:\n    print(res['item_id'], res['distance'], res['metadata']['item_name_flat'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T19:07:27.795110Z","iopub.execute_input":"2025-05-04T19:07:27.795428Z","iopub.status.idle":"2025-05-04T19:07:31.251325Z","shell.execute_reply.started":"2025-05-04T19:07:27.795407Z","shell.execute_reply":"2025-05-04T19:07:31.250012Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4c440d6bcb1c4a4fa8b75becb0b83b23"}},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_31/820911742.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Shoe\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtop_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrag_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfaiss_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minScopeMetadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_k\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_k\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtop_results\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_31/408680452.py\u001b[0m in \u001b[0;36mrag_response\u001b[0;34m(query, faiss_index, model, metadata_df, top_k, final_k)\u001b[0m\n\u001b[1;32m     33\u001b[0m \"\"\"\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopenai_chat_completion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_31/3904678610.py\u001b[0m in \u001b[0;36mopenai_chat_completion\u001b[0;34m(prompt, model, temperature, max_tokens)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mclient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOpenAI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     response = client.chat.completions.create(\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gpt-4\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         messages=[\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_utils/_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m                         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Missing required argument: {quote(missing[0])}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/resources/chat/completions.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    861\u001b[0m     ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[1;32m    862\u001b[0m         \u001b[0mvalidate_response_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m    864\u001b[0m             \u001b[0;34m\"/chat/completions\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m             body=maybe_transform(\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1281\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1282\u001b[0m         )\n\u001b[0;32m-> 1283\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1285\u001b[0m     def patch(\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    958\u001b[0m             \u001b[0mretries_taken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 960\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m    961\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1047\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mremaining_retries\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m                 \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1049\u001b[0;31m                 return self._retry_request(\n\u001b[0m\u001b[1;32m   1050\u001b[0m                     \u001b[0minput_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m                     \u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_retry_request\u001b[0;34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1096\u001b[0m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m   1099\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1047\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mremaining_retries\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m                 \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1049\u001b[0;31m                 return self._retry_request(\n\u001b[0m\u001b[1;32m   1050\u001b[0m                     \u001b[0minput_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m                     \u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_retry_request\u001b[0;34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1096\u001b[0m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m   1099\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1062\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1063\u001b[0m             \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Re-raising status error\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1064\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_status_error_from_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1066\u001b[0m         return self._process_response(\n","\u001b[0;31mRateLimitError\u001b[0m: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}"],"ename":"RateLimitError","evalue":"Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}","output_type":"error"}],"execution_count":42}]}